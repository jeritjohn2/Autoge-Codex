# Data Science Assistant By ModelScope Agent

### Background

[Modelscope-Agent](https://github.com/modelscope/modelscope-agent) is an open source agent Framework, which can access various mainstream open source models through tools such as vllm and ollama, and can also directly call model api. At the same time, RAG components are provided to support developers to quickly access the knowledge base. Finally, the rich tool ecology supports a large number of Modelscope community models as tools,It also supports the direct calling of langchain tools. In addition, it also accesses various commonly used tools, such as web-browsing, Wensheng diagram, code-interpreter and other tools. Based on the above capabilities, Modelscope-Agent supports the open-source GPTs capability -- AgentFabric,It allows more developers to build personal agent assistants interactively without the need for specific code development.

In summary, developers can also freely define agents that meet their own needs based on the Modelscope-Agent framework, and the Data Science Assistant described in this article is an Assistant developed based on the Modelscope-Agent framework to solve Data Science problems.

### Brief introduction

Data Science Assistant (hereinafter referred to as DS Assistant) is a Data Science Assistant developed based on the modelscope-agent framework, which can automatically perform exploratory Data analysis (EDA) in Data Science tasks according to user needs,Data preprocessing, feature engineering, model training, model evaluation and other steps are fully automated.

The traditional ReACT framework is effective for simple tasks, but has several major drawbacks:

1.  Each tool call requires an LLM call.

2.  LLM only Plans 1 sub-issue at a time. This can make the trajectory of the task more uncontrollable, as it is not forced to "reason" about the entire task.


DS Assistant uses the plan-and-excute framework, an emerging Agent framework designed to solve complex tasks efficiently through planning and executing steps.

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1wvqr7Zm6Aa8Oako/img/ed543b70-6690-4d19-b2b8-209963e781c8.png)
*Description of Plan-and-execute Agent on langchain's [website](https://blog.langchain.dev/planning-agents/)*

The following is its workflow:

1.  Task planning: The agent receives the task description input by the user, performs semantic understanding, and decomposes the task into multiple executable subtasks.

2.  Subtask scheduling: intelligently schedules the execution order of subtasks based on the dependencies and priorities between tasks.

3.  Task execution: Each subtask is assigned to a specific module for execution,

4.  Result integration: Summarize the results of each subtask to form the final output and feed it back to the user.

### Quick start
Refer to [DataScience Assistant Quick Start](https://github.com/modelscope/modelscope-agent/blob/master/examples/agents/data_science_assistant.ipynb)


### Architecture Scenario

![/Users/pemppeng/Downloads/Architecture (4).png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/NpQlKaVzEkV0qDvL/img/c64c41b0-5316-46e3-97be-b0477c2a0d5d.png)

The complete system consists of 4 main modules:

1.  Plan module: responsible for generating a series of Task lists according to the user's requirements, and topologically sorting the task sequence to realize

2.  The Execution module is responsible for the specific Execution of the task and saves the Execution result of the task.

3.  The Memory management module records the intermediate execution result, code, and data details of the task.

4.  DS Assistant: as the brain of the whole system, it is responsible for scheduling the operation of the whole system.



## Implementation procedure

1.  Mission planning phase:


At this stage, DS Assistant automatically breaks the complex data science problem into multiple subtasks based on user input. These subtasks are organized and scheduled according to dependencies and priorities (ref:[https://arxiv.org/abs/2402.18679](https://arxiv.org/abs/2402.18679)) to ensure that the execution sequence is logical and efficient.

![/Users/pemppeng/Downloads/Plan (3).png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/NpQlKaVzEkV0qDvL/img/11d9c0a1-4637-4e56-bf63-ad6abf1d96b8.png)

2.  Execution phase: Each subtask is embodied as an executable operation, such as data preprocessing, model training, etc.


![/Users/pemppeng/Downloads/execution (3).png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/NpQlKaVzEkV0qDvL/img/56f843f3-58a8-4427-996f-3aca6db8053b.png)

After all tasks are executed, DS Assistant saves the execution status of the intermediate data (including the code and results generated by each Task, the number of tokens consumed, and the task time) as a file.

## Application cases:

Let's take a concrete example to understand the execution of DS Assistant:

Let's use a competition task on Kaggle ICR-Identifying Age-Related Conditions as an example:

The task is a machine learning task whose main purpose is to identify age-related health conditions by analyzing various data such as medical records, genetic data, lifestyle data, etc. It can help medical professionals identify common health problems in the elderly population early and provide personalized prevention and treatment programs.

First, we need to configure the selected LLM configuration. We have introduced MetaGPT's Data Science Tool and Tool Recommender to recommend the appropriate Data Science Tool to DS assistant based on the task type.

Next, we need to pass the specific requirements of the task to DS Assistant (note that the path to the data file needs to be specified to DS Assistant in the requirements)
```python
from modelscope_agent.agents.data_science_assistant import DataScienceAssistant
from modelscope_agent.tools.metagpt_tools.tool_recommend import TypeMatchToolRecommender

llm_config = {
    'model': 'qwen2-72b-instruct',
    'model_server': 'dashscope',
}
tool_recommender = TypeMatchToolRecommender(tools=["<all>"])
ds_assistant = DataScienceAssistant(llm=llm_config, tool_recommender=tool_recommender)
ds_assistant.run(
    "This is a medical dataset with over fifty anonymized health characteristics linked to three age-related conditions. Your goal is to predict whether a subject has or has not been diagnosed with one of these conditions. The target column is Class. Perform data analysis, data preprocessing, feature engineering, and modeling to predict the target. Report F1 Score on the eval data. Train data path: ‘./dataset/07_icr-identify-age-related-conditions/split_train.csv', eval data path: ‘./dataset/07_icr-identify-age-related-conditions/split_eval.csv' ."
)
```


## Stage of Plan

DS Assistant generates a task list based on user requirements, decomposes the entire data processing process, and then processes the task list in sequence.

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/NpQlKaVzEkV0qDvL/img/14a0d5ae-5183-4acb-8eb1-dbc3e61f5a9d.png)

As you can see, DS Assistant generates five tasks: data exploration, data preprocessing, feature engineering, model training, and prediction.

## The Execute Phase:

### Task 1: Data exploration

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/NpQlKaVzEkV0qDvL/img/d155ac02-22e8-465f-a601-919bf76c8d9c.png)

You can see that the following error is reported when the generated code is executed, because the numpy package is not introduced.

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/NpQlKaVzEkV0qDvL/img/9ca04210-063a-457d-a176-b54b32134237.png)

DS assistant reflects on the error report, regenerates the code and executes it, and successfully outputs the result of data exploration.

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/NpQlKaVzEkV0qDvL/img/c5cceb48-ba81-40a5-a598-764d40aa5b95.png)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/NpQlKaVzEkV0qDvL/img/31886c6f-9cd2-4b9a-813e-28ef1363f7f0.png)

Finally, code judge checks the code to ensure that the generated code logic is correct.

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/NpQlKaVzEkV0qDvL/img/6d461003-a419-4f46-8be7-4d8cba7510b1.png)

### Task 2: Data Preprocessing

In the data preprocessing stage, DS Assistant performs appropriate missing value processing on numeric data and category data respectively, and clears the ID column.

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/NpQlKaVzEkV0qDvL/img/c85283ea-7378-4761-bfa1-7a3e40685b63.png)

### Task 3 feature engineering

After fixing two errors, DS Assistant performs feature engineering on the data and encodes categorical variables.

At the same time, the previously defined categorical\_columns variable is updated to remove the ID column.

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/NpQlKaVzEkV0qDvL/img/bc0135b8-16f2-4da8-8a34-0fd5af1fc679.png)

### Task 4 Model Training

DS Assistant proactively installed the appropriate dependencies and selected multiple models (random forest, gradient boosting, logistic regression) for training, and selected the model with the best results.

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/NpQlKaVzEkV0qDvL/img/88769a75-7cd1-48c9-b866-773c1bc90fa3.png)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/NpQlKaVzEkV0qDvL/img/cda3014f-b18d-40f7-ae22-ac606131da9b.png)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/NpQlKaVzEkV0qDvL/img/911e9c0a-3d40-4a52-b875-e3f3b0636fa2.png)

### Task 5 model validation:

DS Assistant selected the model with the highest F1 score in the training set to test the validation set, and calculated the F1 score of this model on the validation set, successfully completing the task.

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/NpQlKaVzEkV0qDvL/img/f2aa8534-4ec3-4594-a6bc-cb0cca723b09.png)

### Results Save

DS assistant allows you to save the running result as a file of the Jupyter Notebook type and record the intermediate process of running.

Jupyter Notebok

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/NpQlKaVzEkV0qDvL/img/b88c57b4-8d3d-45a3-8357-223f50c64ef5.png)

Intermediate process record JSON file

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/NpQlKaVzEkV0qDvL/img/52df52b1-8a3f-4b25-81c2-16e37336d31a.png)

# Experimental effect

We use[Data Interpreter: An LLM Agent For Data Science](https://arxiv.org/abs/2402.18679)As the test set, the ML-Benchmark of the normal performance score (NPS),total time, and total token are used to evaluate the DS assistant effect.

The Calculation Formula of NPS is as follows:

A Normalized performance score is a method of normalizing performance metrics across tasks or models for easy comparison. In different tasks or model evaluations, different performance metrics may be used, such as accuracy (accuracy), F1 score, ACC (area under the curve), RMSLE (Root mean square log error), and so on.Since the dimensions and optimization directions of these indicators may be different (some are as small as possible, and some are as large as possible), they need to be standardized.

The calculation of a normalized performance Score (NPS) typically involves the following steps:

1.  Determine the optimization direction of the indicator: first determine whether the performance indicator used is "the bigger the better" or "The smaller the better".

2.  Normalized calculation:

    1.  If the metric is "bigger is better" (e. G. Accuracy, F1 score, ACC), then NPS is equal to the original value, because these metrics do not require conversion, and higher values already indicate better performance.

    2.  If the metric is "smaller is better"((e. G. RMSLE), NPS is transformed by a function, such$1/(1+s)$Where s is the original performance value. This conversion ensures that smaller loss values map to higher NPS values close to 1.


Normalized performance scores typically range from 0 to 1, where 1 represents best performance and 0 represents worst performance.

The details and results of the experimental tasks are as follows (green represents the best indicator under the current task)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/NpQlKaVzEkV0qDvL/img/87ac9117-2a9c-478e-988e-2993c47d0017.png)
*ML-Benchmark Task Details*

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/NpQlKaVzEkV0qDvL/img/d751324e-9ac5-4751-a1dd-8f10b9835514.png)
*Comparison of ML-Benchmark effect between DS Assistant and open source SOTA (the effect of open source SOTA refers to the measured value of MetaGPT)*

The results show that in some complex data science tasks, DS Assistant has achieved better results than open source SOTA in terms of normalized performance Score (NPS), task time and token consumption.

Experiment log saved to https://modelscope-agent.oss-cn-hangzhou.aliyuncs.com/resources/DS_Assistant_results.zip

## Conclusion:

All in all, Data Science Assistant can help,

*   Students who are not familiar with the data analysis process but need to analyze the data can quickly understand the ideas and technical points of data processing according to the generated tasks and processing processes.

*   Students who understand the data analysis process, they can influence the data processing method through detailed description, so as to facilitate different experimental reference comparison.

*   Everyone! It can be automated to quickly achieve a deeper understanding of the current file in hand, just ask questions.


Follow-up work

1.  Further improve the success rate of task execution:

    1.  For Code Agent, too much incoming information (error information, intermediate data information, and generated Code information) will reduce the accuracy of model generation Code. LLM can be used to summarize and filter information in the future.

    2.  The same Task can be further decomposed to reduce the requirement for LLM reasoning ability.

2.  Dialogue is interactive, which can separate the task and the execution of the task, promote the task through dialogue, and affect the execution result.

3.  Scenarios that support batch processing of multiple batches of files for the same task.
